# DataBricks
- OSS solution: 
	- Apache Spark
	- Delta Lake
	- mlFlow

- As a company databricks has bet on using delta lakes. 
- Make fun of warehousing
- Competitor is Snowflake
	- Snowflake pushes towards the data science use case whereas data bricks shows says that this is everything. 
- Databricks product design is geared towards helping datascientists as their tools are directly available on Jupyter notebooks
- Delta Tables: ACID transactions![[Screenshot 2025-07-28 at 19.05.02.png]]

## Applications Backend:

Typical Back-End panel interviews We are language agnostic for our interviews, but we do expect fluency in the programming language of your choice (i.e, understanding of core data structures, performance/memory & language constructs). Interviews generally consist of: Coding, Algorithms, System Programming, Architecture, Domain Deep Dive, and Cross-Functional
- [Coding] This implementation-focused interview evaluates your ability to write production-quality code. You’ll be expected to develop functional solutions with clean code organization, comprehensive test coverage, and careful edge case handling. We’ll assess your practical knowledge of algorithms and data structures, along with your ability to analyze solution efficiency using Big-O notation.
- [Algorithm] This algorithm and data structures interview assesses computer science fundamentals, your analytical reasoning ,and your problem-solving methodology. You’ll implement solutions while focusing on algorithmic efficiency and appropriate data structure selection. We expect you to analyze time/space complexity using Big-O notation, demonstrate comprehensive testing strategies, and clearly articulate your approach to edge cases and design decisions.
- [System Programming] This systems programming interview evaluates your understanding of core concepts, including multi-threading, synchronization, I/O operations, and performance optimization. You’ll be asked to design and implement system components using pseudocode, demonstrating knowledge of fundamental systems primitives (files, buffering, caching, storage, concurrency) and their practical applications. We’ll cover both single-threaded and multi-threaded approaches, with emphasis on code design principles such as separation of concerns, cohesion, coupling, and the single responsibility principle. While specific language proficiency isn’t required, you should be prepared to write detailed pseudocode to explore various technical trade-offs and solutions.
- [Architecture] This high-level architectural design interview evaluates your ability to conceptualize end-to-end systems from database to UI. You’ll likely whiteboard with CoderPad Draw and create comprehensive system designs that address scalability, reliability, component interactions, and request flows. We expect strong technical judgment, clear articulation of trade-offs, and in-depth knowledge of storage systems, distributed computing concepts, and interface design. The discussion may encompass APIs, networking, concurrency, caching, replication, consistency models, and failure handling. You should demonstrate the ability to design robust, scalable solutions while collaboratively defining requirements and justifying your architectural decisions.
- [Domain Deep Dive] This in-depth technical conversational interview explores your experience with architectural and scaling challenges you’ve solved. We’ll examine your problem-solving approach, technical decision-making, and domain expertise. You may be asked to work through a relevant architectural problem related to your background, though it can be leveraged. The goal is to facilitate a meaningful technical exchange where both interviewer and candidate gain new perspectives within your technical domain.
- [Cross-Functional/Hiring Manager] This behavioral interview will be conducted by one of our Engineering Leaders, potentially your direct manager. The conversation will explore your career trajectory, job search motivations, and interest in Databricks. You’ll discuss significant projects you’ve contributed to and how they aligned with broader company objectives, along with your approach to problem-solving, decision-making, and professional growth. We’re also interested in your experiences with cross-team collaboration, overcoming challenges, and leadership qualities relevant to your career level. While this isn’t a technical assessment, please be prepared to explain your projects with technical depth, avoiding company-specific terminology that might not be familiar to those outside your current organization.

## Applications Database:

Typical Database interviews Interviews generally consist of: Coding, Algorithms, Architecture or Storage, System Programming, Domain Deep Dive, Database Papers, and Cross-Functional
- [Storage] This open-ended design interview evaluates candidates for engineering roles on our storage layer team. The deliberately broad requirements allow you to demonstrate your ability to bring clarity to ambiguous problems, propose and iterate on storage layer designs, and address technical challenges with thoughtful solutions. Be prepared to assess trade-offs, optimizations, and how your design would evolve to meet changing requirements. We value both technical depth and the ability to explain complex concepts in accessible terms.
- [Stream Processing] This technical interview evaluates candidates with database and/or distributed systems expertise, focusing on real-time data processing architectures. You’ll be asked to design solutions for data ingestion pipelines for real-time systems, storage optimization for high-throughput environments, and query processing mechanisms with low-latency requirements. Be prepared to discuss trade-offs, optimizations, scalability considerations, and fault tolerance. We’ll evaluate how your design addresses both immediate needs and future growth, as well as your ability to explain complex concepts in accessible terms. We’re looking for systematic thinking paired with practical implementation knowledge. 
- [Databases Papers] This seminar-style interview will evaluate your database expertise, focusing on query optimization and execution strategies. This open-book assessment allows you to reference your notes and the original paper during the discussion. Be prepared to address questions about storage optimization techniques, runtime performance improvements, and general database performance enhancement methods. This module is specifically designed for engineers with database experience to demonstrate their understanding of advanced optimization concepts.
- [Cross-Functional/Hiring Manager] This behavioral interview will be conducted by one of our Engineering Leaders, potentially your direct manager. The conversation will explore your career trajectory, job search motivations, and interest in Databricks. You’ll discuss significant projects you’ve contributed to and how they aligned with broader company objectives, along with your approach to problem-solving, decision-making, and professional growth. We’re also interested in your experiences with cross-team collaboration, overcoming challenges, and leadership qualities relevant to your career level. While this isn’t a technical assessment, please be prepared to explain your projects with technical depth, avoiding company-specific terminology that might not be familiar to those outside your current organization.